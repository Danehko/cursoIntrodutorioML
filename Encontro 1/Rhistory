demo()
?sin
x <- seq(-3, 7, by = 1/8)
tx <- cbind(x, cos(pi*x), cospi(x), sin(pi*x), sinpi(x),
tan(pi*x), tanpi(x), deparse.level=2)
op <- options(digits = 4, width = 90) # for nice formatting
head(tx)
tx[ (x %% 1) %in% c(0, 0.5) ,]
options(op)
plot(x)
clear
print("olÃ¡")
library(caTools)
library(RWeka)
library(caTools)
library(RWeka)
install.packages("RWeka")
library(RWeka)
install.packages("rJava")
library(rJava)
library("RWekajars", lib.loc="~/R/win-library/3.4")
library("reshape2", lib.loc="~/R/win-library/3.4")
detach("package:RWekajars", unload=TRUE)
detach("package:reshape2", unload=TRUE)
library("lava", lib.loc="~/R/win-library/3.4")
detach("package:lava", unload=TRUE)
library("munsell", lib.loc="~/R/win-library/3.4")
detach("package:munsell", unload=TRUE)
install.packages('rJava')
library(rJava)
library(RWeka)
library(RWekajars)
library(RWeka)
install.packages("RWeka")
install.packages('caTools')
library(RWeka)
install.packages("rJava")
install.packages("rJava")
library(rJava)
library(rJava)
setwd("C:/Users/neto/Dropbox/Curso ML Ministrados/Curso ML Embrapii/Encontro 1")
subject_name <- c("John Doe", "Jane Doe", "Steve Graves")
temperature <- c(98.1, 98.6, 101.4)
flu_status <- c(FALSE, FALSE, TRUE)
temperature[2]
temperature[2:3]
temperature[-2]
temperature[c(TRUE, TRUE, TRUE)]
temperature[c(TRUE, FALSE, TRUE)]
gender <- factor(c("MALE", "FEMALE", "MALE"))
gender
blood <- factor(c("O", "AB", "A"),
levels = c("A", "B", "AB", "O"))
blood
symptoms <- factor(c("SEVERE", "MILD", "MODERATE"),
levels = c("MILD", "MODERATE", "SEVERE"),
ordered = TRUE)
symptoms
symptoms >= "MODERATE"
symptoms > "MODERATE"
subject_name[1]
temperature[1]
flu_status[1]
gender[1]
blood[1]
symptoms[1]
subject1 <- list(fullname = subject_name[1],
temperature = temperature[1],
flu_status = flu_status[1],
gender = gender[1],
blood = blood[1],
symptoms = symptoms[1])
subject1
subject1[2]
subject1[[2]]
subject1$temperature
gg = subject1[2]
gg
gg = subject1[[2]]
subject1[c("temperature", "flu_status")]
ddd=subject1[c("temperature", "flu_status")]
pt_data <- data.frame(subject_name, temperature, flu_status, gender,
blood, symptoms, stringsAsFactors = FALSE)
View(pt_data)
pt_data[c("temperature", "flu_status")]
pt_data[2:3]
pt_data[ , ]
pt_data[c(1, 3), c("temperature", "gender")]
pt_data[-2, c(-1, -3, -5, -6)]
setwd("C:/Users/neto/Dropbox/Curso ML Ministrados/Arquivos_Livro_MLwR/Machine Learning with R (2nd Ed.)/Chapter 03")
wbcd <- read.csv("wisc_bc_data.csv", stringsAsFactors = FALSE)
View(wbcd)
wbcd <- wbcd[-1]
View(wbcd)
table(wbcd$diagnosis)
View(wbcd)
wbcd$diagnosis <- factor(wbcd$diagnosis, levels = c("B", "M"),
labels = c("Benign", "Malignant"))
round(prop.table(table(wbcd$diagnosis)) * 100, digits = 1)
round(prop.table(table(wbcd$diagnosis)) * 100, digits = 2)
round(prop.table(table(wbcd$diagnosis)) * 100, digits = 1)
round(prop.table(table(wbcd$diagnosis)) * 100, digits = 2)
round(prop.table(table(wbcd$diagnosis)) , digits = 2)
summary(wbcd[c("radius_mean", "area_mean", "smoothness_mean")])
summary(wbcd)
View(wbcd)
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
normalize(c(1, 2, 3, 4, 5))
normalize(c(10, 20, 30, 40, 50))
wbcd_n <- (apply(wbcd[2:31], normalize)
d
wbcd_n <- (lapply(wbcd[2:31], normalize))
wbcd_n <- as.data.frame(lapply(wbcd[2:31], normalize))
summary(wbcd_n$area_mean)
wbcd_train <- wbcd_n[1:469, ]
wbcd_test <- wbcd_n[470:569, ]
View(wbcd_train)
View(wbcd)
wbcd_train <- wbcd_n[1:469, ]
wbcd_test <- wbcd_n[470:569, ]
View(wbcd_train)
wbcd_train_labels <- wbcd[1:469, 1]
wbcd_test_labels <- wbcd[470:569, 1]
library(class)
wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test,
cl = wbcd_train_labels, k = 21)
library(gmodels)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,
prop.chisq = FALSE)
install.packages("gmodels")
library(gmodels)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,
prop.chisq = FALSE)
wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test,
cl = wbcd_train_labels, k = 1)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,
prop.chisq = FALSE)
wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test,
cl = wbcd_train_labels, k = 21)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,
prop.chisq = TRUE)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,
prop.chisq = FALSE)
setwd("C:/Users/neto/OneDrive/Cursos/Machine Learning A-Z/Part 3 - Classification/Section 15 - K-Nearest Neighbors (K-NN)")
dataset = read.csv('Social_Network_Ads.csv')
View(dataset)
dataset = dataset[3:5]
View(dataset)
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors = FALSE)
setwd("C:/Users/neto/Dropbox/Curso ML Ministrados/Curso ML Embrapii/Encontro 1")
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors = FALSE)
str(sms_raw)
sms_raw$type <- factor(sms_raw$type)
str(sms_raw)
str(sms_raw$type)
table(sms_raw$type)
library(tm)
install.packages("tm")
library(tm)
sms_corpus <- VCorpus(VectorSource(sms_raw$text))
print(sms_corpus)
inspect(sms_corpus[1:2])
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:2], as.character)
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:3], as.character)
sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))
as.character(sms_corpus[[1]])
as.character(sms_corpus_clean[[1]])
sms_corpus_clean <- tm_map(sms_corpus_clean, removeNumbers) # remove numbers
sms_corpus_clean <- tm_map(sms_corpus_clean, removeWords, stopwords()) # remove stop words
sms_corpus_clean <- tm_map(sms_corpus_clean, removePunctuation) # remove punctuation
library(SnowballC)
install.packages("SnowballC")
library(SnowballC)
wordStem(c("learn", "learned", "learning", "learns"))
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)
sms_corpus_clean <- tm_map(sms_corpus_clean, stripWhitespace) # eliminate unneeded whitespace
lapply(sms_corpus[1:3], as.character)
lapply(sms_corpus_clean[1:3], as.character)
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test  <- sms_dtm[4170:5559, ]
sms_train_labels <- sms_raw[1:4169, ]$type
sms_test_labels  <- sms_raw[4170:5559, ]$type
prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))
install.packages("wordcloud")
library(wordcloud)
wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE)
spam <- subset(sms_raw, type == "spam")
ham  <- subset(sms_raw, type == "ham")
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
sms_dtm_freq_train <- removeSparseTerms(sms_dtm_train, 0.999)
findFreqTerms(sms_dtm_train, 5)
sms_freq_words <- findFreqTerms(sms_dtm_train, 5)
str(sms_freq_words)
sms_dtm_freq_train <- sms_dtm_train[ , sms_freq_words]
sms_dtm_freq_test <- sms_dtm_test[ , sms_freq_words]
convert_counts <- function(x) {
x <- ifelse(x > 0, "Yes", "No")
}
sms_train <- apply(sms_dtm_freq_train, MARGIN = 2, convert_counts)
sms_test  <- apply(sms_dtm_freq_test, MARGIN = 2, convert_counts)
install.packages("e1071")
library(e1071)
sms_classifier <- naiveBayes(sms_train, sms_train_labels)
sms_test_pred <- predict(sms_classifier, sms_test)
library(gmodels)
CrossTable(sms_test_pred, sms_test_labels,
prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
dnn = c('predicted', 'actual'))
